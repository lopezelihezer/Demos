{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69d01138",
   "metadata": {},
   "source": [
    "# Image Processing in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "591dbad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58732207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74a43f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e2c8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ddd56b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 8, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42215fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images[-2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aa6b44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0, 2.0, 10.0, 7.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 14.0, 16.0, 16.0, 15.0, 1.0, 0.0],\n",
       " [0.0, 4.0, 16.0, 7.0, 3.0, 16.0, 7.0, 0.0],\n",
       " [0.0, 5.0, 16.0, 10.0, 7.0, 16.0, 4.0, 0.0],\n",
       " [0.0, 0.0, 5.0, 14.0, 14.0, 16.0, 4.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 2.0, 0.0],\n",
       " [0.0, 0.0, 4.0, 7.0, 7.0, 16.0, 2.0, 0.0],\n",
       " [0.0, 0.0, 5.0, 12.0, 16.0, 12.0, 0.0, 0.0]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images[-2].reshape(8,8).tolist()\n",
    "# here we see the darkness of each pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b31bbb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x166b08592e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "myimg = digits.images[-2]\n",
    "plt.imshow(myimg, cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16da5e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numSamples = len(digits.images)\n",
    "data = digits.data\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c773b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "myEstimator = svm.SVC(gamma=0.001, C=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4f96b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, gamma=0.001)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myEstimator.fit(data[:int(numSamples/2)], digits.target[:int(numSamples/2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83bc035b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myEstimator.predict(data[-2:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d02c0de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digits.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "092a9c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "898"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(numSamples/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab2080a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  2., ..., 14.,  0.,  0.],\n",
       "       [ 0.,  1., 12., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  3.,  0.,  0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:898]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e3130f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1108e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
